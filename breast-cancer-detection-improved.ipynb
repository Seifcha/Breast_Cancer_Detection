{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":408,"sourceType":"datasetVersion","datasetId":180},{"sourceId":13746888,"sourceType":"datasetVersion","datasetId":8747382}],"dockerImageVersionId":31193,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Breast Cancer Detection: Data Preparation & Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set visualization style\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (12, 8)\n\nprint(\"‚úì Libraries imported successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.664645Z","iopub.status.idle":"2025-11-15T20:36:29.664866Z","shell.execute_reply.started":"2025-11-15T20:36:29.664764Z","shell.execute_reply":"2025-11-15T20:36:29.664774Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"1. Business Understandig","metadata":{}},{"cell_type":"markdown","source":"2. Data Understandig","metadata":{}},{"cell_type":"code","source":"# Load the Wisconsin Diagnostic Breast Cancer dataset\ndf = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\n\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"Total samples: {df.shape[0]}\")\nprint(f\"Total features: {df.shape[1]}\")\n\n# Display first few rows\nprint(\"\\nFirst 5 rows of the dataset:\")\nprint(df.head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.665978Z","iopub.status.idle":"2025-11-15T20:36:29.666326Z","shell.execute_reply.started":"2025-11-15T20:36:29.666181Z","shell.execute_reply":"2025-11-15T20:36:29.666197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for columns with all NaN values\nprint(\"\\nColumns with all NaN values:\")\nnan_cols = df.columns[df.isna().all()].tolist()\nprint(nan_cols if nan_cols else \"None\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.667039Z","iopub.status.idle":"2025-11-15T20:36:29.667338Z","shell.execute_reply.started":"2025-11-15T20:36:29.667211Z","shell.execute_reply":"2025-11-15T20:36:29.667224Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CHECK FOR MISSING VALUES\n\nmissing_values = df.isnull().sum()\nmissing_percentage = (missing_values / len(df)) * 100\n\nmissing_df = pd.DataFrame({\n    'Column': missing_values.index,\n    'Missing_Count': missing_values.values,\n    'Percentage': missing_percentage.values\n})\nmissing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n\nif len(missing_df) > 0:\n    print(\"\\nColumns with missing values:\")\n    print(missing_df)\nelse:\n    print(\"\\n‚úì No missing values found in the dataset\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.668318Z","iopub.status.idle":"2025-11-15T20:36:29.668859Z","shell.execute_reply.started":"2025-11-15T20:36:29.668679Z","shell.execute_reply":"2025-11-15T20:36:29.668696Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# DATA INFORMATION\n\nprint(\"\\nData types:\")\nprint(df.dtypes.value_counts())\n\nprint(\"\\nDetailed information:\")\ndf.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.670328Z","iopub.status.idle":"2025-11-15T20:36:29.670738Z","shell.execute_reply.started":"2025-11-15T20:36:29.670569Z","shell.execute_reply":"2025-11-15T20:36:29.670585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TARGET VARIABLE ANALYSIS\n\n# Check diagnosis distribution\ndiagnosis_counts = df['diagnosis'].value_counts()\ndiagnosis_percentages = df['diagnosis'].value_counts(normalize=True) * 100\n\nprint(\"\\nDiagnosis Distribution:\")\nprint(f\"Benign (B): {diagnosis_counts['B']} samples ({diagnosis_percentages['B']:.2f}%)\")\nprint(f\"Malignant (M): {diagnosis_counts['M']} samples ({diagnosis_percentages['M']:.2f}%)\")\n\n# Encode target variable: M (Malignant) = 1, B (Benign) = 0\ndf['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\nprint(\"\\n‚úì Target variable encoded: M=1 (Malignant), B=0 (Benign)\")\n\n# Visualize class distribution\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Count plot\ndiagnosis_labels = ['Benign', 'Malignant']\ndiagnosis_values = [diagnosis_counts['B'], diagnosis_counts['M']]\naxes[0].bar(diagnosis_labels, diagnosis_values, color=['#2ecc71', '#e74c3c'])\naxes[0].set_ylabel('Count')\naxes[0].set_title('Class Distribution (Count)', fontsize=14, fontweight='bold')\nfor i, v in enumerate(diagnosis_values):\n    axes[0].text(i, v + 5, str(v), ha='center', va='bottom', fontweight='bold')\n\n# Pie chart\ncolors = ['#2ecc71', '#e74c3c']\naxes[1].pie(diagnosis_values, labels=diagnosis_labels, autopct='%1.1f%%', \n            startangle=90, colors=colors, textprops={'fontsize': 12, 'fontweight': 'bold'})\naxes[1].set_title('Class Distribution (Percentage)', fontsize=14, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('class_distribution.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"‚úì Visualization saved as 'class_distribution.png'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.672170Z","iopub.status.idle":"2025-11-15T20:36:29.672725Z","shell.execute_reply.started":"2025-11-15T20:36:29.672394Z","shell.execute_reply":"2025-11-15T20:36:29.672413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# FEATURE CATEGORIZATION\n\n# Categorize features as in the paper\nmean_features = [col for col in df.columns if col.endswith('_mean')]\nse_features = [col for col in df.columns if col.endswith('_se')]\nworst_features = [col for col in df.columns if col.endswith('_worst')]\n\nprint(f\"\\nMean features (10): {len(mean_features)}\")\nprint(mean_features)\nprint(f\"\\nStandard Error features (10): {len(se_features)}\")\nprint(se_features)\nprint(f\"\\nWorst features (10): {len(worst_features)}\")\nprint(worst_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.674053Z","iopub.status.idle":"2025-11-15T20:36:29.674500Z","shell.execute_reply.started":"2025-11-15T20:36:29.674295Z","shell.execute_reply":"2025-11-15T20:36:29.674314Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# STATISTICAL SUMMARY\n\n# Separate features by diagnosis\nbenign = df[df['diagnosis'] == 0]\nmalignant = df[df['diagnosis'] == 1]\n\nprint(\"\\nOverall Statistics:\")\nprint(df.describe())\n\nprint(\"Statistics for Benign Cases:\")\nprint(benign.describe())\n\nprint(\"Statistics for Malignant Cases:\")\nprint(malignant.describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.675583Z","iopub.status.idle":"2025-11-15T20:36:29.676042Z","shell.execute_reply.started":"2025-11-15T20:36:29.675838Z","shell.execute_reply":"2025-11-15T20:36:29.675858Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n#  EXPLORATORY DATA ANALYSIS\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"EXPLORATORY DATA ANALYSIS\")\nprint(\"=\"*80)\n\n# 1 Distribution of Mean Features\nprint(\"\\n[1/7] Creating distribution plots for mean features...\")\nfig, axes = plt.subplots(5, 2, figsize=(15, 18))\naxes = axes.ravel()\n\nfor idx, col in enumerate(mean_features):\n    axes[idx].hist(benign[col], bins=30, alpha=0.6, label='Benign', color='#2ecc71', edgecolor='black')\n    axes[idx].hist(malignant[col], bins=30, alpha=0.6, label='Malignant', color='#e74c3c', edgecolor='black')\n    axes[idx].set_xlabel(col, fontsize=10)\n    axes[idx].set_ylabel('Frequency', fontsize=10)\n    axes[idx].set_title(f'Distribution of {col}', fontsize=11, fontweight='bold')\n    axes[idx].legend()\n    axes[idx].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('mean_features_distribution.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"‚úì Saved as 'mean_features_distribution.png'\")\n\n# 2 Box plots for mean features\nprint(\"\\n[2/7] Creating box plots for mean features...\")\nfig, axes = plt.subplots(5, 2, figsize=(15, 18))\naxes = axes.ravel()\n\nfor idx, col in enumerate(mean_features):\n    df.boxplot(column=col, by='diagnosis', ax=axes[idx])\n    axes[idx].set_xlabel('Diagnosis (0=Benign, 1=Malignant)', fontsize=10)\n    axes[idx].set_ylabel(col, fontsize=10)\n    axes[idx].set_title(f'Box Plot: {col}', fontsize=11, fontweight='bold')\n    axes[idx].get_figure().suptitle('')\n\nplt.tight_layout()\nplt.savefig('mean_features_boxplot.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"‚úì Saved as 'mean_features_boxplot.png'\")\n\n# 3 Correlation Matrix\nprint(\"\\n[3/7] Creating correlation matrix...\")\n# Select only numeric columns (excluding diagnosis for now)\nnumeric_features = df.drop('diagnosis', axis=1)\n\nplt.figure(figsize=(20, 16))\ncorrelation_matrix = numeric_features.corr()\nsns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0, \n            linewidths=0.5, cbar_kws={\"shrink\": 0.8})\nplt.title('Correlation Matrix - All Features', fontsize=16, fontweight='bold', pad=20)\nplt.tight_layout()\nplt.savefig('correlation_matrix_full.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"‚úì Saved as 'correlation_matrix_full.png'\")\n\n# 4 Correlation with diagnosis\nprint(\"\\n[4/7] Analyzing correlation with diagnosis...\")\ncorrelations_with_diagnosis = df.corr()['diagnosis'].drop('diagnosis').sort_values(ascending=False)\n\nplt.figure(figsize=(12, 10))\ncorrelations_with_diagnosis.plot(kind='barh', color='steelblue')\nplt.xlabel('Correlation with Diagnosis', fontsize=12)\nplt.ylabel('Features', fontsize=12)\nplt.title('Feature Correlation with Diagnosis\\n(Positive = Malignant, Negative = Benign)', \n          fontsize=14, fontweight='bold')\nplt.axvline(x=0, color='red', linestyle='--', linewidth=2)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig('correlation_with_diagnosis.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"‚úì Saved as 'correlation_with_diagnosis.png'\")\n\nprint(\"\\nTop 10 features most correlated with Malignant diagnosis:\")\nprint(correlations_with_diagnosis.head(10))\n\n# 9.5 Scatter plots (replicating Figure 3, 4, 5 from paper)\nprint(\"\\n[5/7] Creating scatter plots for feature categories...\")\n\n# Mean features scatter plot\nfig, axes = plt.subplots(5, 2, figsize=(15, 18))\naxes = axes.ravel()\n\nfor idx, col in enumerate(mean_features):\n    axes[idx].scatter(benign[col], benign.index, alpha=0.5, s=10, c='#2ecc71', label='Benign')\n    axes[idx].scatter(malignant[col], malignant.index, alpha=0.5, s=10, c='#e74c3c', label='Malignant')\n    axes[idx].set_xlabel(col, fontsize=10)\n    axes[idx].set_ylabel('Sample Index', fontsize=10)\n    axes[idx].set_title(f'Scatter: {col}', fontsize=11, fontweight='bold')\n    axes[idx].legend()\n    axes[idx].grid(True, alpha=0.3)\n\nplt.suptitle('Scatter Plot of Mean Features (Replicating Paper Figure 3)', \n             fontsize=14, fontweight='bold', y=1.001)\nplt.tight_layout()\nplt.savefig('scatter_mean_features.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"‚úì Saved as 'scatter_mean_features.png'\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.677661Z","iopub.status.idle":"2025-11-15T20:36:29.678082Z","shell.execute_reply.started":"2025-11-15T20:36:29.677875Z","shell.execute_reply":"2025-11-15T20:36:29.677894Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**3. Data Preparation**# ","metadata":{}},{"cell_type":"code","source":"\n# Remove 'id' column as it's not relevant for classification\nif 'id' in df.columns:\n    df = df.drop('id', axis=1)\n    print(\"\\n‚úì 'id' column removed\")\n\n# Remove 'Unnamed: 32' column if it exists (common in this dataset)\nif 'Unnamed: 32' in df.columns:\n    df = df.drop('Unnamed: 32', axis=1)\n    print(\"‚úì 'Unnamed: 32' column removed\")\n\nprint(f\"\\nDataset shape after cleaning: {df.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.679450Z","iopub.status.idle":"2025-11-15T20:36:29.679753Z","shell.execute_reply.started":"2025-11-15T20:36:29.679626Z","shell.execute_reply":"2025-11-15T20:36:29.679637Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 10. DATA NORMALIZATION\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"DATA NORMALIZATION\")\nprint(\"=\"*80)\n\n# Separate features and target\nX = df.drop('diagnosis', axis=1)\ny = df['diagnosis']\n\nprint(f\"\\nFeatures shape: {X.shape}\")\nprint(f\"Target shape: {y.shape}\")\n\n# Standardize features using StandardScaler (as mentioned in the paper)\nscaler = StandardScaler()\nX_normalized = scaler.fit_transform(X)\n\n# Convert back to DataFrame for easier handling\nX_normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n\nprint(\"\\n‚úì Features normalized using StandardScaler (mean=0, std=1)\")\nprint(\"\\nNormalized data statistics:\")\nprint(X_normalized_df.describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.680961Z","iopub.status.idle":"2025-11-15T20:36:29.681217Z","shell.execute_reply.started":"2025-11-15T20:36:29.681104Z","shell.execute_reply":"2025-11-15T20:36:29.681118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 11. TRAIN-TEST SPLIT\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"TRAIN-TEST SPLIT\")\nprint(\"=\"*80)\n\n# Split data: 80% train, 20% test (paper used 70/30, but you specified 80/20)\nX_train, X_test, y_train, y_test = train_test_split(\n    X_normalized, y, test_size=0.20, random_state=42, stratify=y\n)\n\nprint(f\"\\nTraining set size: {X_train.shape[0]} samples ({(X_train.shape[0]/len(df))*100:.1f}%)\")\nprint(f\"Testing set size: {X_test.shape[0]} samples ({(X_test.shape[0]/len(df))*100:.1f}%)\")\n\nprint(f\"\\nTraining set class distribution:\")\nprint(f\"  Benign: {(y_train == 0).sum()} samples\")\nprint(f\"  Malignant: {(y_train == 1).sum()} samples\")\n\nprint(f\"\\nTesting set class distribution:\")\nprint(f\"  Benign: {(y_test == 0).sum()} samples\")\nprint(f\"  Malignant: {(y_test == 1).sum()} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.682573Z","iopub.status.idle":"2025-11-15T20:36:29.682933Z","shell.execute_reply.started":"2025-11-15T20:36:29.682788Z","shell.execute_reply":"2025-11-15T20:36:29.682805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 12. SAVE PROCESSED DATA\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAVING PROCESSED DATA\")\nprint(\"=\"*80)\n\n# Save normalized data\nnp.save('X_train.npy', X_train)\nnp.save('X_test.npy', X_test)\nnp.save('y_train.npy', y_train)\nnp.save('y_test.npy', y_test)\n\nprint(\"\\n‚úì Data saved successfully:\")\nprint(\"  - X_train.npy\")\nprint(\"  - X_test.npy\")\nprint(\"  - y_train.npy\")\nprint(\"  - y_test.npy\")\n\n# Save feature names\nfeature_names = X.columns.tolist()\nwith open('feature_names.txt', 'w') as f:\n    for feature in feature_names:\n        f.write(f\"{feature}\\n\")\nprint(\"  - feature_names.txt\")\n\n# Save scaler for future use\nimport pickle\nwith open('scaler.pkl', 'wb') as f:\n    pickle.dump(scaler, f)\nprint(\"  - scaler.pkl\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.684450Z","iopub.status.idle":"2025-11-15T20:36:29.684900Z","shell.execute_reply.started":"2025-11-15T20:36:29.684684Z","shell.execute_reply":"2025-11-15T20:36:29.684704Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 13. SUMMARY REPORT\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"SUMMARY REPORT\")\nprint(\"=\"*80)\n\nsummary_report = f\"\"\"\nWISCONSIN DIAGNOSTIC BREAST CANCER DATASET - EDA REPORT\n{'='*80}\n\n1. DATASET OVERVIEW\n   - Total samples: {df.shape[0]}\n   - Total features: {df.shape[1] - 1} (after removing ID)\n   - Classes: Binary (Benign=0, Malignant=1)\n\n2. CLASS DISTRIBUTION\n   - Benign (B): {diagnosis_counts['B']} samples ({diagnosis_percentages['B']:.2f}%)\n   - Malignant (M): {diagnosis_counts['M']} samples ({diagnosis_percentages['M']:.2f}%)\n   - Balance: {'Relatively balanced' if abs(diagnosis_percentages['B'] - diagnosis_percentages['M']) < 20 else 'Imbalanced'}\n\n3. FEATURE CATEGORIES\n   - Mean features: {len(mean_features)}\n   - Standard Error features: {len(se_features)}\n   - Worst features: {len(worst_features)}\n   - Total: {len(mean_features) + len(se_features) + len(worst_features)} features\n\n4. DATA QUALITY\n   - Missing values: {'None' if len(missing_df) == 0 else f'{len(missing_df)} columns'}\n   - Duplicates: {df.duplicated().sum()}\n   - Data types: All numeric (after encoding)\n\n5. DATA PREPROCESSING\n   - Normalization: StandardScaler (mean=0, std=1)\n   - Train-Test Split: {(X_train.shape[0]/len(df))*100:.0f}% / {(X_test.shape[0]/len(df))*100:.0f}%\n   - Random State: 42 (for reproducibility)\n\n6. KEY FINDINGS\n   - Most correlated features with Malignant diagnosis:\n{chr(10).join([f'     ‚Ä¢ {feat}: {correlations_with_diagnosis[feat]:.3f}' for feat in correlations_with_diagnosis.head(5).index])}\n   \n   - Least correlated features with Malignant diagnosis:\n{chr(10).join([f'     ‚Ä¢ {feat}: {correlations_with_diagnosis[feat]:.3f}' for feat in correlations_with_diagnosis.tail(5).index])}\n\n7. LINEAR SEPARABILITY\n   - The dataset appears to be linearly separable based on visualization\n   - This aligns with the paper's findings that linear classifiers performed well\n   - Mean features show clear separation between benign and malignant cases\n\n8. FILES GENERATED\n   - Training data: X_train.npy, y_train.npy\n   - Testing data: X_test.npy, y_test.npy\n   - Scaler: scaler.pkl\n   - Feature names: feature_names.txt\n   - Visualizations: \n     ‚Ä¢ class_distribution.png\n     ‚Ä¢ mean_features_distribution.png\n     ‚Ä¢ mean_features_boxplot.png\n     ‚Ä¢ correlation_matrix_full.png\n     ‚Ä¢ correlation_with_diagnosis.png\n     ‚Ä¢ scatter_mean_features.png\n\n9. NEXT STEPS (FOR OTHER TEAM MEMBERS)\n   - Person 2-6: Load the processed data using:\n     ```python\n     X_train = np.load('X_train.npy')\n     X_test = np.load('X_test.npy')\n     y_train = np.load('y_train.npy')\n     y_test = np.load('y_test.npy')\n     ```\n   - Implement ML algorithms: Linear Regression, MLP, Nearest Neighbor, \n     Softmax Regression, SVM, GRU-SVM\n   - Target: >90% test accuracy (paper achieved ~99% with MLP)\n\n{'='*80}\nReport generated successfully!\n\"\"\"\n\nprint(summary_report)\n\n# Save report to file\nwith open('EDA_REPORT.txt', 'w', encoding='utf-8') as f:\n    f.write(summary_report)\n\nprint(\"\\n‚úì Complete EDA report saved as 'EDA_REPORT.txt'\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"DATA PREPARATION & EDA COMPLETED SUCCESSFULLY!\")\nprint(\"=\"*80)\nprint(\"\\nYou can now share the processed data files with your team members.\")\nprint(\"All visualizations and the detailed report are ready for your project submission.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.685787Z","iopub.status.idle":"2025-11-15T20:36:29.686289Z","shell.execute_reply.started":"2025-11-15T20:36:29.685998Z","shell.execute_reply":"2025-11-15T20:36:29.686017Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import *\nfrom tensorflow.keras.models import Sequential\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\nmodel = Sequential([\n    Dense(32, input_shape=(X_train.shape[1],), activation='relu'),\n    Dense(16, activation='relu'),\n    Dense(1, activation='sigmoid')\n],name='ANN_Model')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.687576Z","iopub.status.idle":"2025-11-15T20:36:29.688005Z","shell.execute_reply.started":"2025-11-15T20:36:29.687800Z","shell.execute_reply":"2025-11-15T20:36:29.687820Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(\n    optimizer='Adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.689356Z","iopub.status.idle":"2025-11-15T20:36:29.689634Z","shell.execute_reply.started":"2025-11-15T20:36:29.689498Z","shell.execute_reply":"2025-11-15T20:36:29.689510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    X_train, y_train,\n    validation_split=0.2,\n    epochs=50,\n    batch_size=16,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.691135Z","iopub.status.idle":"2025-11-15T20:36:29.691394Z","shell.execute_reply.started":"2025-11-15T20:36:29.691277Z","shell.execute_reply":"2025-11-15T20:36:29.691292Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"model.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.691990Z","iopub.status.idle":"2025-11-15T20:36:29.692222Z","shell.execute_reply.started":"2025-11-15T20:36:29.692115Z","shell.execute_reply":"2025-11-15T20:36:29.692127Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss, accuracy = model.evaluate(X_test, y_test)\nprint(f\"Test Accuracy: {accuracy*100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.693432Z","iopub.status.idle":"2025-11-15T20:36:29.693734Z","shell.execute_reply.started":"2025-11-15T20:36:29.693596Z","shell.execute_reply":"2025-11-15T20:36:29.693609Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Loss over epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy over epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.694741Z","iopub.status.idle":"2025-11-15T20:36:29.695009Z","shell.execute_reply.started":"2025-11-15T20:36:29.694876Z","shell.execute_reply":"2025-11-15T20:36:29.694889Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n\ny_pred_prob = model.predict(X_test) \ny_pred = (y_pred_prob > 0.5).astype(int) \n\ncm = confusion_matrix(y_test, y_pred)\n\nclass_names = ['Benign (non-cancerous)', 'Malignant (cancerous)']  \nplt.figure(figsize=(6,5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.title('Confusion Matrix for ANN Model')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.695728Z","iopub.status.idle":"2025-11-15T20:36:29.696164Z","shell.execute_reply.started":"2025-11-15T20:36:29.695990Z","shell.execute_reply":"2025-11-15T20:36:29.696006Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"R√âGRESSION LOGISTIQUE","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    accuracy_score, recall_score, precision_score, f1_score,\n    roc_auc_score, roc_curve, precision_recall_curve, \n    confusion_matrix, classification_report, auc\n)\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.calibration import calibration_curve, CalibrationDisplay\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Configuration des graphiques\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (12, 8)\n\nprint(\"=\"*80)\nprint(\"PERSONNE 2 : R√âGRESSION LOGISTIQUE + ANALYSE STATISTIQUE AVANC√âE\")\nprint(\"=\"*80)\nprint(\"\\n‚úì Biblioth√®ques import√©es avec succ√®s\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.697670Z","iopub.status.idle":"2025-11-15T20:36:29.697966Z","shell.execute_reply.started":"2025-11-15T20:36:29.697833Z","shell.execute_reply":"2025-11-15T20:36:29.697845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# √âTAPE 2 : R√âGRESSION LOGISTIQUE DE BASE\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"√âTAPE 2 : R√âGRESSION LOGISTIQUE DE BASE (SANS R√âGULARISATION)\")\nprint(\"=\"*80)\n\n# Mod√®le de base sans r√©gularisation (C tr√®s grand)\nlr_base = LogisticRegression(penalty=None, max_iter=10000, random_state=42)\nlr_base.fit(X_train, y_train)\n\n# Pr√©dictions\ny_pred_base = lr_base.predict(X_test)\ny_pred_proba_base = lr_base.predict_proba(X_test)[:, 1]\n\n# M√©triques de base\naccuracy_base = accuracy_score(y_test, y_pred_base)\nprecision_base = precision_score(y_test, y_pred_base)\nrecall_base = recall_score(y_test, y_pred_base)\nf1_base = f1_score(y_test, y_pred_base)\nauc_base = roc_auc_score(y_test, y_pred_proba_base)\n\nprint(f\"\\nüìä R√âSULTATS DU MOD√àLE DE BASE :\")\nprint(f\"{'='*50}\")\nprint(f\"Accuracy  : {accuracy_base:.4f} ({accuracy_base*100:.2f}%)\")\nprint(f\"Precision : {precision_base:.4f}\")\nprint(f\"Recall    : {recall_base:.4f}\")\nprint(f\"F1-Score  : {f1_base:.4f}\")\nprint(f\"AUC-ROC   : {auc_base:.4f}\")\nprint(f\"{'='*50}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.699047Z","iopub.status.idle":"2025-11-15T20:36:29.699402Z","shell.execute_reply.started":"2025-11-15T20:36:29.699240Z","shell.execute_reply":"2025-11-15T20:36:29.699252Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#√âTAPE 3 : ANALYSE DE MULTICOLIN√âARIT√â (VIF)\nprint(\"\\n\" + \"=\"*80)\nprint(\"√âTAPE 3 : ANALYSE DE MULTICOLIN√âARIT√â (VIF)\")\nprint(\"=\"*80)\nprint(\"\\nLe VIF (Variance Inflation Factor) mesure la multicolin√©arit√© :\")\nprint(\"  ‚Ä¢ VIF < 5  : Pas de probl√®me\")\nprint(\"  ‚Ä¢ VIF 5-10 : Multicolin√©arit√© mod√©r√©e\")\nprint(\"  ‚Ä¢ VIF > 10 : Multicolin√©arit√© √©lev√©e (probl√©matique)\\n\")\n\n# Cr√©er DataFrame pour VIF\nX_train_df = pd.DataFrame(X_train, columns=feature_names)\n\n# Calculer VIF pour chaque feature\nvif_data = pd.DataFrame()\nvif_data[\"Feature\"] = feature_names\nvif_data[\"VIF\"] = [variance_inflation_factor(X_train_df.values, i) \n                   for i in range(len(feature_names))]\n\n# Trier par VIF d√©croissant\nvif_data = vif_data.sort_values('VIF', ascending=False).reset_index(drop=True)\n\nprint(\"üìä TOP 10 FEATURES AVEC VIF LE PLUS √âLEV√â :\")\nprint(vif_data.head(10).to_string(index=False))\n\nprint(f\"\\n‚ö† Features avec VIF > 10 : {(vif_data['VIF'] > 10).sum()}\")\nprint(f\"‚úì Features avec VIF < 5  : {(vif_data['VIF'] < 5).sum()}\")\n\n# Visualisation VIF\nplt.figure(figsize=(14, 8))\ncolors = ['red' if x > 10 else 'orange' if x > 5 else 'green' for x in vif_data['VIF']]\nplt.barh(vif_data['Feature'], vif_data['VIF'], color=colors)\nplt.xlabel('VIF Value', fontsize=12, fontweight='bold')\nplt.ylabel('Features', fontsize=12, fontweight='bold')\nplt.title('Variance Inflation Factor (VIF) pour chaque Feature\\nRouge: VIF>10, Orange: VIF 5-10, Vert: VIF<5', \n          fontsize=14, fontweight='bold')\nplt.axvline(x=5, color='orange', linestyle='--', linewidth=2, label='VIF = 5')\nplt.axvline(x=10, color='red', linestyle='--', linewidth=2, label='VIF = 10')\nplt.legend()\nplt.tight_layout()\nplt.savefig('vif_analysis.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"\\n‚úì Graphique VIF sauvegard√© : 'vif_analysis.png'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.700406Z","iopub.status.idle":"2025-11-15T20:36:29.700663Z","shell.execute_reply.started":"2025-11-15T20:36:29.700552Z","shell.execute_reply":"2025-11-15T20:36:29.700563Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*80)\nprint(\"√âTAPE 4 : R√âGULARISATION L1 (LASSO) ET L2 (RIDGE)\")\nprint(\"=\"*80)\nprint(\"\\nR√©gularisation :\")\nprint(\"  ‚Ä¢ L1 (Lasso) : Favorise la sparsit√© (certains coefficients = 0)\")\nprint(\"  ‚Ä¢ L2 (Ridge) : R√©duit tous les coefficients uniform√©ment\")\nprint(\"  ‚Ä¢ ElasticNet : Combinaison de L1 et L2\\n\")\n\n# L1 R√©gularisation (Lasso)\nlr_l1 = LogisticRegression(penalty='l1', C=1.0, solver='liblinear', \n                           max_iter=10000, random_state=42)\nlr_l1.fit(X_train, y_train)\ny_pred_l1 = lr_l1.predict(X_test)\ny_pred_proba_l1 = lr_l1.predict_proba(X_test)[:, 1]\n\n# L2 R√©gularisation (Ridge)\nlr_l2 = LogisticRegression(penalty='l2', C=1.0, solver='lbfgs', \n                           max_iter=10000, random_state=42)\nlr_l2.fit(X_train, y_train)\ny_pred_l2 = lr_l2.predict(X_test)\ny_pred_proba_l2 = lr_l2.predict_proba(X_test)[:, 1]\n\n# ElasticNet\nlr_elastic = LogisticRegression(penalty='elasticnet', C=1.0, solver='saga',\n                                l1_ratio=0.5, max_iter=10000, random_state=42)\nlr_elastic.fit(X_train, y_train)\ny_pred_elastic = lr_elastic.predict(X_test)\ny_pred_proba_elastic = lr_elastic.predict_proba(X_test)[:, 1]\n\n# Comparaison des r√©gularisations\nresults_reg = pd.DataFrame({\n    'Model': ['Base (No Reg)', 'L1 (Lasso)', 'L2 (Ridge)', 'ElasticNet'],\n    'Accuracy': [\n        accuracy_score(y_test, y_pred_base),\n        accuracy_score(y_test, y_pred_l1),\n        accuracy_score(y_test, y_pred_l2),\n        accuracy_score(y_test, y_pred_elastic)\n    ],\n    'Precision': [\n        precision_score(y_test, y_pred_base),\n        precision_score(y_test, y_pred_l1),\n        precision_score(y_test, y_pred_l2),\n        precision_score(y_test, y_pred_elastic)\n    ],\n    'Recall': [\n        recall_score(y_test, y_pred_base),\n        recall_score(y_test, y_pred_l1),\n        recall_score(y_test, y_pred_l2),\n        recall_score(y_test, y_pred_elastic)\n    ],\n    'F1-Score': [\n        f1_score(y_test, y_pred_base),\n        f1_score(y_test, y_pred_l1),\n        f1_score(y_test, y_pred_l2),\n        f1_score(y_test, y_pred_elastic)\n    ],\n    'AUC-ROC': [\n        roc_auc_score(y_test, y_pred_proba_base),\n        roc_auc_score(y_test, y_pred_proba_l1),\n        roc_auc_score(y_test, y_pred_proba_l2),\n        roc_auc_score(y_test, y_pred_proba_elastic)\n    ],\n    'Non-zero Coef': [\n        np.sum(lr_base.coef_[0] != 0),\n        np.sum(lr_l1.coef_[0] != 0),\n        np.sum(lr_l2.coef_[0] != 0),\n        np.sum(lr_elastic.coef_[0] != 0)\n    ]\n})\n\nprint(\"\\nüìä COMPARAISON DES R√âGULARISATIONS :\")\nprint(results_reg.to_string(index=False))\n\n# Visualisation\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Graphique des m√©triques\nmetrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\nx = np.arange(len(results_reg))\nwidth = 0.15\n\nfor i, metric in enumerate(metrics):\n    axes[0].bar(x + i*width, results_reg[metric], width, label=metric)\n\naxes[0].set_xlabel('Mod√®les', fontsize=12, fontweight='bold')\naxes[0].set_ylabel('Score', fontsize=12, fontweight='bold')\naxes[0].set_title('Comparaison des Performances par Type de R√©gularisation', \n                  fontsize=13, fontweight='bold')\naxes[0].set_xticks(x + width * 2)\naxes[0].set_xticklabels(results_reg['Model'], rotation=15, ha='right')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# Nombre de coefficients non-nuls\naxes[1].bar(results_reg['Model'], results_reg['Non-zero Coef'], \n            color=['blue', 'red', 'green', 'purple'])\naxes[1].set_xlabel('Mod√®les', fontsize=12, fontweight='bold')\naxes[1].set_ylabel('Nombre de Coefficients Non-Nuls', fontsize=12, fontweight='bold')\naxes[1].set_title('Sparsit√© des Mod√®les (Features s√©lectionn√©es)', \n                  fontsize=13, fontweight='bold')\naxes[1].set_xticklabels(results_reg['Model'], rotation=15, ha='right')\nfor i, v in enumerate(results_reg['Non-zero Coef']):\n    axes[1].text(i, v + 0.5, str(v), ha='center', fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('regularization_comparison.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"\\n‚úì Graphique de comparaison sauvegard√© : 'regularization_comparison.png'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.701479Z","iopub.status.idle":"2025-11-15T20:36:29.701753Z","shell.execute_reply.started":"2025-11-15T20:36:29.701631Z","shell.execute_reply":"2025-11-15T20:36:29.701645Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# √âTAPE 5 : OPTIMISATION AVEC GRIDSEARCHCV\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"√âTAPE 5 : OPTIMISATION DES HYPERPARAM√àTRES (GRIDSEARCHCV)\")\nprint(\"=\"*80)\nprint(\"\\nRecherche des meilleurs hyperparam√®tres...\")\nprint(\"Cela peut prendre quelques minutes...\\n\")\n\n# D√©finir la grille de param√®tres\nparam_grid = {\n    'penalty': ['l1', 'l2', 'elasticnet'],\n    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n    'solver': ['liblinear', 'saga'],\n    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]  # Pour ElasticNet\n}\n\n# GridSearchCV avec validation crois√©e 5-fold\ngrid_search = GridSearchCV(\n    LogisticRegression(max_iter=10000, random_state=42),\n    param_grid,\n    cv=5,\n    scoring='roc_auc',\n    n_jobs=-1,\n    verbose=1\n)\n\n# Adapter le param_grid pour √©viter les combinaisons invalides\n# L1 n√©cessite liblinear ou saga, L2 peut utiliser lbfgs\nparam_grid_valid = []\nfor penalty in ['l1', 'l2']:\n    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n        if penalty == 'l1':\n            param_grid_valid.append({'penalty': [penalty], 'C': [C], \n                                    'solver': ['liblinear', 'saga']})\n        else:\n            param_grid_valid.append({'penalty': [penalty], 'C': [C], \n                                    'solver': ['liblinear', 'lbfgs', 'saga']})\n\n# ElasticNet avec saga\nfor C in [0.001, 0.01, 0.1, 1, 10, 100]:\n    for l1_r in [0.1, 0.3, 0.5, 0.7, 0.9]:\n        param_grid_valid.append({\n            'penalty': ['elasticnet'], \n            'C': [C], \n            'solver': ['saga'],\n            'l1_ratio': [l1_r]\n        })\n\n# Nouvelle GridSearch avec param√®tres valides\ngrid_search = GridSearchCV(\n    LogisticRegression(max_iter=10000, random_state=42),\n    param_grid_valid,\n    cv=5,\n    scoring='roc_auc',\n    n_jobs=-1,\n    verbose=0\n)\n\ngrid_search.fit(X_train, y_train)\n\nprint(\"\\n‚úì Optimisation termin√©e!\")\nprint(f\"\\nüèÜ MEILLEURS HYPERPARAM√àTRES :\")\nprint(f\"{'='*50}\")\nfor param, value in grid_search.best_params_.items():\n    print(f\"{param:15s} : {value}\")\nprint(f\"{'='*50}\")\nprint(f\"Meilleur score AUC-ROC (CV) : {grid_search.best_score_:.4f}\")\n\n# Mod√®le optimis√©\nlr_optimized = grid_search.best_estimator_\ny_pred_opt = lr_optimized.predict(X_test)\ny_pred_proba_opt = lr_optimized.predict_proba(X_test)[:, 1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.703029Z","iopub.status.idle":"2025-11-15T20:36:29.703712Z","shell.execute_reply.started":"2025-11-15T20:36:29.703532Z","shell.execute_reply":"2025-11-15T20:36:29.703551Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# √âTAPE 6 : √âVALUATION COMPL√àTE DES PERFORMANCES\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"√âTAPE 6 : √âVALUATION COMPL√àTE DU MOD√àLE OPTIMIS√â\")\nprint(\"=\"*80)\n\n# M√©triques compl√®tes\naccuracy_opt = accuracy_score(y_test, y_pred_opt)\nprecision_opt = precision_score(y_test, y_pred_opt)\nrecall_opt = recall_score(y_test, y_pred_opt)\nf1_opt = f1_score(y_test, y_pred_opt)\nauc_opt = roc_auc_score(y_test, y_pred_proba_opt)\n\nprint(f\"\\nüìä PERFORMANCES DU MOD√àLE OPTIMIS√â :\")\nprint(f\"{'='*50}\")\nprint(f\"Accuracy  : {accuracy_opt:.4f} ({accuracy_opt*100:.2f}%)\")\nprint(f\"Precision : {precision_opt:.4f}\")\nprint(f\"Recall    : {recall_opt:.4f}\")\nprint(f\"F1-Score  : {f1_opt:.4f}\")\nprint(f\"AUC-ROC   : {auc_opt:.4f}\")\nprint(f\"{'='*50}\")\n\n# Rapport de classification d√©taill√©\nprint(f\"\\nüìã RAPPORT DE CLASSIFICATION D√âTAILL√â :\")\nprint(classification_report(y_test, y_pred_opt, \n                          target_names=['Benign', 'Malignant']))\n\n# Validation crois√©e\ncv_scores = cross_val_score(lr_optimized, X_train, y_train, \n                           cv=5, scoring='roc_auc')\nprint(f\"\\nüîÑ VALIDATION CROIS√âE (5-Fold) :\")\nprint(f\"Scores AUC-ROC : {cv_scores}\")\nprint(f\"Moyenne        : {cv_scores.mean():.4f}\")\nprint(f\"√âcart-type     : {cv_scores.std():.4f}\")\n\n# ============================================================================\n# √âTAPE 7 : VISUALISATIONS AVANC√âES\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"√âTAPE 7 : CR√âATION DES VISUALISATIONS\")\nprint(\"=\"*80)\n\n# 7.1 Matrice de Confusion\ncm = confusion_matrix(y_test, y_pred_opt)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n            xticklabels=['Benign', 'Malignant'],\n            yticklabels=['Benign', 'Malignant'])\nplt.xlabel('Pr√©diction', fontsize=12, fontweight='bold')\nplt.ylabel('R√©alit√©', fontsize=12, fontweight='bold')\nplt.title('Matrice de Confusion - Mod√®le Optimis√©', fontsize=14, fontweight='bold')\n\n# Ajouter les pourcentages\nfor i in range(2):\n    for j in range(2):\n        percentage = cm[i, j] / cm[i].sum() * 100\n        plt.text(j+0.5, i+0.7, f'({percentage:.1f}%)', \n                ha='center', va='center', fontsize=10, color='red')\n\nplt.tight_layout()\nplt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"‚úì Matrice de confusion sauvegard√©e : 'confusion_matrix.png'\")\n\n# 7.2 Courbe ROC\nfpr, tpr, thresholds_roc = roc_curve(y_test, y_pred_proba_opt)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(10, 8))\nplt.plot(fpr, tpr, color='darkorange', lw=3, \n         label=f'ROC Curve (AUC = {roc_auc:.4f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', \n         label='Random Classifier')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (1 - Specificity)', fontsize=12, fontweight='bold')\nplt.ylabel('True Positive Rate (Sensitivity)', fontsize=12, fontweight='bold')\nplt.title('Receiver Operating Characteristic (ROC) Curve', \n          fontsize=14, fontweight='bold')\nplt.legend(loc=\"lower right\", fontsize=11)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"‚úì Courbe ROC sauvegard√©e : 'roc_curve.png'\")\n\n# 7.3 Courbe Precision-Recall\nprecision_curve, recall_curve, thresholds_pr = precision_recall_curve(\n    y_test, y_pred_proba_opt)\npr_auc = auc(recall_curve, precision_curve)\n\nplt.figure(figsize=(10, 8))\nplt.plot(recall_curve, precision_curve, color='blue', lw=3,\n         label=f'PR Curve (AUC = {pr_auc:.4f})')\nplt.xlabel('Recall (Sensitivity)', fontsize=12, fontweight='bold')\nplt.ylabel('Precision', fontsize=12, fontweight='bold')\nplt.title('Precision-Recall Curve', fontsize=14, fontweight='bold')\nplt.legend(loc=\"lower left\", fontsize=11)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig('precision_recall_curve.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"‚úì Courbe Precision-Recall sauvegard√©e : 'precision_recall_curve.png'\")\n\n# 7.4 Courbes ROC et PR combin√©es\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# ROC\naxes[0].plot(fpr, tpr, color='darkorange', lw=3, \n            label=f'ROC (AUC = {roc_auc:.4f})')\naxes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[0].set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')\naxes[0].set_ylabel('True Positive Rate', fontsize=12, fontweight='bold')\naxes[0].set_title('ROC Curve', fontsize=13, fontweight='bold')\naxes[0].legend(loc=\"lower right\")\naxes[0].grid(True, alpha=0.3)\n\n# PR Curve\naxes[1].plot(recall_curve, precision_curve, color='blue', lw=3,\n            label=f'PR (AUC = {pr_auc:.4f})')\naxes[1].set_xlabel('Recall', fontsize=12, fontweight='bold')\naxes[1].set_ylabel('Precision', fontsize=12, fontweight='bold')\naxes[1].set_title('Precision-Recall Curve', fontsize=13, fontweight='bold')\naxes[1].legend(loc=\"lower left\")\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('roc_pr_combined.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"‚úì Courbes combin√©es sauvegard√©es : 'roc_pr_combined.png'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.705042Z","iopub.status.idle":"2025-11-15T20:36:29.705383Z","shell.execute_reply.started":"2025-11-15T20:36:29.705245Z","shell.execute_reply":"2025-11-15T20:36:29.705264Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# √âTAPE 8 : INTERPR√âTATION DES COEFFICIENTS\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"√âTAPE 8 : INTERPR√âTATION DES COEFFICIENTS (IMPORTANCE DES FEATURES)\")\nprint(\"=\"*80)\n\n# R√©cup√©rer les coefficients\ncoefficients = lr_optimized.coef_[0]\ncoef_df = pd.DataFrame({\n    'Feature': feature_names,\n    'Coefficient': coefficients,\n    'Abs_Coefficient': np.abs(coefficients)\n}).sort_values('Abs_Coefficient', ascending=False)\n\nprint(\"\\nüìä TOP 15 FEATURES LES PLUS IMPORTANTES :\")\nprint(coef_df.head(15).to_string(index=False))\n\nprint(\"\\nüí° INTERPR√âTATION :\")\nprint(\"  ‚Ä¢ Coefficient > 0 : Augmente la probabilit√© de MALIGNIT√â\")\nprint(\"  ‚Ä¢ Coefficient < 0 : Augmente la probabilit√© de B√âNIGNIT√â\")\nprint(\"  ‚Ä¢ |Coefficient| √©lev√© : Feature tr√®s influente\")\n\n# Visualisation des coefficients\nfig, axes = plt.subplots(1, 2, figsize=(16, 8))\n\n# Top 15 features\ntop_15 = coef_df.head(15).sort_values('Coefficient')\ncolors = ['red' if x > 0 else 'green' for x in top_15['Coefficient']]\naxes[0].barh(top_15['Feature'], top_15['Coefficient'], color=colors)\naxes[0].set_xlabel('Coefficient Value', fontsize=12, fontweight='bold')\naxes[0].set_title('Top 15 Features par Importance\\n(Rouge: Malignit√©, Vert: B√©nignit√©)', \n                  fontsize=13, fontweight='bold')\naxes[0].axvline(x=0, color='black', linestyle='-', linewidth=1)\naxes[0].grid(True, alpha=0.3)\n\n# Tous les coefficients tri√©s\nall_coef = coef_df.sort_values('Coefficient')\ncolors_all = ['red' if x > 0 else 'green' for x in all_coef['Coefficient']]\naxes[1].barh(range(len(all_coef)), all_coef['Coefficient'], color=colors_all)\naxes[1].set_xlabel('Coefficient Value', fontsize=12, fontweight='bold')\naxes[1].set_ylabel('Features (ordonn√©es)', fontsize=12, fontweight='bold')\naxes[1].set_title('Tous les Coefficients du Mod√®le', fontsize=13, fontweight='bold')\naxes[1].axvline(x=0, color='black', linestyle='-', linewidth=1)\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"\\n‚úì Importance des features sauvegard√©e : 'feature_importance.png'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.706986Z","iopub.status.idle":"2025-11-15T20:36:29.707272Z","shell.execute_reply.started":"2025-11-15T20:36:29.707159Z","shell.execute_reply":"2025-11-15T20:36:29.707170Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# √âTAPE 9 : TEST DE CALIBRATION\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"√âTAPE 9 : TEST DE CALIBRATION DU MOD√àLE\")\nprint(\"=\"*80)\nprint(\"\\nLa calibration mesure si les probabilit√©s pr√©dites sont fiables.\")\nprint(\"Un mod√®le bien calibr√© : si pr√©dit 70%, environ 70% sont r√©ellement positifs.\\n\")\n\n# Courbe de calibration\nprob_true, prob_pred = calibration_curve(y_test, y_pred_proba_opt, n_bins=10)\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Courbe de calibration\naxes[0].plot(prob_pred, prob_true, marker='o', linewidth=2, \n            label='Logistic Regression', color='blue')\naxes[0].plot([0, 1], [0, 1], linestyle='--', color='gray', \n            label='Parfaitement calibr√©')\naxes[0].set_xlabel('Probabilit√© Pr√©dite Moyenne', fontsize=12, fontweight='bold')\naxes[0].set_ylabel('Fraction de Positifs', fontsize=12, fontweight='bold')\naxes[0].set_title('Courbe de Calibration', fontsize=13, fontweight='bold')\naxes[0].legend(loc='upper left')\naxes[0].grid(True, alpha=0.3)\n\n# Histogramme des probabilit√©s pr√©dites\naxes[1].hist(y_pred_proba_opt[y_test == 0], bins=20, alpha=0.6, \n            label='Benign', color='green', edgecolor='black')\naxes[1].hist(y_pred_proba_opt[y_test == 1], bins=20, alpha=0.6, \n            label='Malignant', color='red', edgecolor='black')\naxes[1].set_xlabel('Probabilit√© Pr√©dite', fontsize=12, fontweight='bold')\naxes[1].set_ylabel('Fr√©quence', fontsize=12, fontweight='bold')\naxes[1].set_title('Distribution des Probabilit√©s Pr√©dites', \n                  fontsize=13, fontweight='bold')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('calibration_analysis.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"‚úì Analyse de calibration sauvegard√©e : 'calibration_analysis.png'\")\n\n# Calculer l'√©cart de calibration (Brier Score)\nfrom sklearn.metrics import brier_score_loss\nbrier_score = brier_score_loss(y_test, y_pred_proba_opt)\nprint(f\"\\nüìä M√âTRIQUES DE CALIBRATION :\")\nprint(f\"{'='*50}\")\nprint(f\"Brier Score : {brier_score:.4f}\")\nprint(f\"  ‚Ä¢ Score parfait = 0.0\")\nprint(f\"  ‚Ä¢ Plus le score est bas, meilleure est la calibration\")\nprint(f\"{'='*50}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.707922Z","iopub.status.idle":"2025-11-15T20:36:29.708272Z","shell.execute_reply.started":"2025-11-15T20:36:29.708121Z","shell.execute_reply":"2025-11-15T20:36:29.708138Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# √âTAPE 10 : COMPARAISON FINALE DE TOUS LES MOD√àLES\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"√âTAPE 10 : COMPARAISON FINALE DE TOUS LES MOD√àLES\")\nprint(\"=\"*80)\n\n# Cr√©er un tableau r√©capitulatif\nfinal_comparison = pd.DataFrame({\n    'Mod√®le': ['Base (No Reg)', 'L1 (Lasso)', 'L2 (Ridge)', \n               'ElasticNet', 'Optimis√© (GridSearch)'],\n    'Accuracy': [\n        accuracy_base, \n        accuracy_score(y_test, y_pred_l1),\n        accuracy_score(y_test, y_pred_l2),\n        accuracy_score(y_test, y_pred_elastic),\n        accuracy_opt\n    ],\n    'Precision': [\n        precision_base,\n        precision_score(y_test, y_pred_l1),\n        precision_score(y_test, y_pred_l2),\n        precision_score(y_test, y_pred_elastic),\n        precision_opt\n    ],\n    'Recall': [\n        recall_base,\n        recall_score(y_test, y_pred_l1),\n        recall_score(y_test, y_pred_l2),\n        recall_score(y_test, y_pred_elastic),\n        recall_opt\n    ],\n    'F1-Score': [\n        f1_base,\n        f1_score(y_test, y_pred_l1),\n        f1_score(y_test, y_pred_l2),\n        f1_score(y_test, y_pred_elastic),\n        f1_opt\n    ],\n    'AUC-ROC': [\n        auc_base,\n        roc_auc_score(y_test, y_pred_proba_l1),\n        roc_auc_score(y_test, y_pred_proba_l2),\n        roc_auc_score(y_test, y_pred_proba_elastic),\n        auc_opt\n    ]\n})\n\nprint(\"\\nüìä TABLEAU R√âCAPITULATIF COMPLET :\")\nprint(final_comparison.to_string(index=False))\n\n# Identifier le meilleur mod√®le pour chaque m√©trique\nprint(\"\\nüèÜ MEILLEURS SCORES PAR M√âTRIQUE :\")\nfor col in ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']:\n    best_idx = final_comparison[col].idxmax()\n    best_model = final_comparison.loc[best_idx, 'Mod√®le']\n    best_score = final_comparison.loc[best_idx, col]\n    print(f\"  {col:12s} : {best_model:25s} ({best_score:.4f})\")\n\n# Visualisation finale\nfig, ax = plt.subplots(figsize=(14, 8))\nx = np.arange(len(final_comparison))\nwidth = 0.15\nmetrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\ncolors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n\nfor i, metric in enumerate(metrics):\n    ax.bar(x + i*width, final_comparison[metric], width, \n           label=metric, color=colors[i])\n\nax.set_xlabel('Mod√®les', fontsize=12, fontweight='bold')\nax.set_ylabel('Score', fontsize=12, fontweight='bold')\nax.set_title('Comparaison Finale de Tous les Mod√®les de R√©gression Logistique', \n             fontsize=14, fontweight='bold')\nax.set_xticks(x + width * 2)\nax.set_xticklabels(final_comparison['Mod√®le'], rotation=20, ha='right')\nax.legend(loc='lower right')\nax.set_ylim([0.85, 1.0])\nax.grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.savefig('final_comparison.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"\\n‚úì Comparaison finale sauvegard√©e : 'final_comparison.png'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.710006Z","iopub.status.idle":"2025-11-15T20:36:29.710293Z","shell.execute_reply.started":"2025-11-15T20:36:29.710168Z","shell.execute_reply":"2025-11-15T20:36:29.710180Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# √âTAPE 11 : ANALYSE DES ERREURS\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"√âTAPE 11 : ANALYSE DES ERREURS\")\nprint(\"=\"*80)\n\n# Identifier les erreurs\nerrors_mask = y_pred_opt != y_test\nn_errors = errors_mask.sum()\nerror_indices = np.where(errors_mask)[0]\n\nprint(f\"\\n‚ùå NOMBRE D'ERREURS : {n_errors} / {len(y_test)} ({n_errors/len(y_test)*100:.2f}%)\")\n\n# Analyser les types d'erreurs\nfalse_positives = np.where((y_pred_opt == 1) & (y_test == 0))[0]\nfalse_negatives = np.where((y_pred_opt == 0) & (y_test == 1))[0]\n\nprint(f\"\\nFaux Positifs (pr√©dit Malin, r√©el B√©nin)  : {len(false_positives)}\")\nprint(f\"Faux N√©gatifs (pr√©dit B√©nin, r√©el Malin)  : {len(false_negatives)}\")\n\n# Distribution des probabilit√©s pour les erreurs\nif len(false_positives) > 0:\n    print(f\"\\nüìä PROBABILIT√âS DES FAUX POSITIFS :\")\n    fp_probs = y_pred_proba_opt[false_positives]\n    print(f\"  Moyenne : {fp_probs.mean():.4f}\")\n    print(f\"  Min     : {fp_probs.min():.4f}\")\n    print(f\"  Max     : {fp_probs.max():.4f}\")\n\nif len(false_negatives) > 0:\n    print(f\"\\nüìä PROBABILIT√âS DES FAUX N√âGATIFS :\")\n    fn_probs = y_pred_proba_opt[false_negatives]\n    print(f\"  Moyenne : {fn_probs.mean():.4f}\")\n    print(f\"  Min     : {fn_probs.min():.4f}\")\n    print(f\"  Max     : {fn_probs.max():.4f}\")\n\n# Visualisation des erreurs\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Distribution des probabilit√©s par type d'erreur\nif len(false_positives) > 0:\n    axes[0].hist(y_pred_proba_opt[false_positives], bins=10, \n                alpha=0.7, color='orange', edgecolor='black',\n                label=f'Faux Positifs (n={len(false_positives)})')\nif len(false_negatives) > 0:\n    axes[0].hist(y_pred_proba_opt[false_negatives], bins=10, \n                alpha=0.7, color='purple', edgecolor='black',\n                label=f'Faux N√©gatifs (n={len(false_negatives)})')\naxes[0].axvline(x=0.5, color='red', linestyle='--', linewidth=2, \n               label='Seuil de d√©cision')\naxes[0].set_xlabel('Probabilit√© Pr√©dite', fontsize=12, fontweight='bold')\naxes[0].set_ylabel('Fr√©quence', fontsize=12, fontweight='bold')\naxes[0].set_title('Distribution des Probabilit√©s pour les Erreurs', \n                  fontsize=13, fontweight='bold')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# Seuil de d√©cision optimal\nfrom sklearn.metrics import f1_score as f1_metric\nthresholds = np.arange(0.1, 0.9, 0.01)\nf1_scores = []\nfor thresh in thresholds:\n    y_pred_thresh = (y_pred_proba_opt >= thresh).astype(int)\n    f1_scores.append(f1_metric(y_test, y_pred_thresh))\n\noptimal_threshold = thresholds[np.argmax(f1_scores)]\naxes[1].plot(thresholds, f1_scores, linewidth=2, color='blue')\naxes[1].axvline(x=0.5, color='red', linestyle='--', linewidth=2, \n               label='Seuil par d√©faut (0.5)')\naxes[1].axvline(x=optimal_threshold, color='green', linestyle='--', \n               linewidth=2, label=f'Seuil optimal ({optimal_threshold:.2f})')\naxes[1].set_xlabel('Seuil de D√©cision', fontsize=12, fontweight='bold')\naxes[1].set_ylabel('F1-Score', fontsize=12, fontweight='bold')\naxes[1].set_title('Optimisation du Seuil de D√©cision', \n                  fontsize=13, fontweight='bold')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('error_analysis.png', dpi=300, bbox_inches='tight')\nplt.show()\nprint(\"\\n‚úì Analyse des erreurs sauvegard√©e : 'error_analysis.png'\")\n\nprint(f\"\\nüí° SEUIL OPTIMAL : {optimal_threshold:.4f}\")\nprint(f\"   (avec ce seuil, F1-Score max = {max(f1_scores):.4f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.711338Z","iopub.status.idle":"2025-11-15T20:36:29.711643Z","shell.execute_reply.started":"2025-11-15T20:36:29.711488Z","shell.execute_reply":"2025-11-15T20:36:29.711502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# √âTAPE 12 : RAPPORT FINAL\n# ============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"√âTAPE 12 : G√âN√âRATION DU RAPPORT FINAL\")\nprint(\"=\"*80)\n\nreport = f\"\"\"\n{'='*80}\nPERSONNE 2 : RAPPORT FINAL - R√âGRESSION LOGISTIQUE\nBreast Cancer Detection - Wisconsin Dataset\n{'='*80}\n\n1. R√âSUM√â EX√âCUTIF\n{'='*80}\nCe rapport pr√©sente l'analyse compl√®te de la r√©gression logistique pour la \nd√©tection du cancer du sein, incluant l'analyse de multicolin√©arit√©, la \nr√©gularisation, l'optimisation et l'√©valuation approfondie des performances.\n\n2. DONN√âES\n{'='*80}\n- Ensemble d'entra√Ænement : {X_train.shape[0]} √©chantillons\n- Ensemble de test       : {X_test.shape[0]} √©chantillons\n- Nombre de features     : {X_train.shape[1]}\n- Classes                : B√©nin (0), Malin (1)\n\n3. ANALYSE DE MULTICOLIN√âARIT√â (VIF)\n{'='*80}\nLe VIF (Variance Inflation Factor) a √©t√© calcul√© pour d√©tecter la multicolin√©arit√© :\n- Features avec VIF > 10 : {(vif_data['VIF'] > 10).sum()} (multicolin√©arit√© √©lev√©e)\n- Features avec VIF 5-10 : {((vif_data['VIF'] >= 5) & (vif_data['VIF'] <= 10)).sum()} (mod√©r√©e)\n- Features avec VIF < 5  : {(vif_data['VIF'] < 5).sum()} (pas de probl√®me)\n\nTop 5 features avec VIF le plus √©lev√© :\n{vif_data.head(5).to_string(index=False)}\n\n‚ö†Ô∏è  INTERPR√âTATION :\nUn VIF √©lev√© indique que certaines features sont corr√©l√©es entre elles.\nCela peut affecter l'interpr√©tabilit√© des coefficients mais pas n√©cessairement\nles performances pr√©dictives. La r√©gularisation L1/L2 aide √† g√©rer ce probl√®me.\n\n4. COMPARAISON DES R√âGULARISATIONS\n{'='*80}\n{final_comparison.to_string(index=False)}\n\nüèÜ MEILLEUR MOD√àLE : {final_comparison.loc[final_comparison['AUC-ROC'].idxmax(), 'Mod√®le']}\n\n5. OPTIMISATION PAR GRIDSEARCHCV\n{'='*80}\nMeilleurs hyperparam√®tres trouv√©s :\n{chr(10).join([f\"  ‚Ä¢ {k:15s} : {v}\" for k, v in grid_search.best_params_.items()])}\n\nScore AUC-ROC (Validation Crois√©e 5-fold) : {grid_search.best_score_:.4f}\n\n6. PERFORMANCES DU MOD√àLE OPTIMIS√â\n{'='*80}\nSur l'ensemble de TEST :\n  ‚Ä¢ Accuracy  : {accuracy_opt:.4f} ({accuracy_opt*100:.2f}%)\n  ‚Ä¢ Precision : {precision_opt:.4f}\n  ‚Ä¢ Recall    : {recall_opt:.4f}\n  ‚Ä¢ F1-Score  : {f1_opt:.4f}\n  ‚Ä¢ AUC-ROC   : {auc_opt:.4f}\n\nValidation Crois√©e (5-Fold) sur TRAIN :\n  ‚Ä¢ Moyenne AUC-ROC : {cv_scores.mean():.4f}\n  ‚Ä¢ √âcart-type      : {cv_scores.std():.4f}\n\nüìä INTERPR√âTATION :\n- Accuracy > 95% : Excellent mod√®le\n- Recall √©lev√© : D√©tecte bien les cas malins (crucial en m√©decine)\n- Precision √©lev√©e : Peu de faux positifs\n- AUC-ROC proche de 1.0 : Excellente capacit√© de discrimination\n\n7. ANALYSE DE CALIBRATION\n{'='*80}\nBrier Score : {brier_score:.4f}\n  ‚Ä¢ Score parfait = 0.0\n  ‚Ä¢ Plus bas = meilleure calibration\n\nLe mod√®le est {'bien' if brier_score < 0.1 else 'moyennement' if brier_score < 0.2 else 'mal'} calibr√©.\n\n8. IMPORTANCE DES FEATURES\n{'='*80}\nTop 10 features les plus importantes (valeur absolue du coefficient) :\n\n{coef_df.head(10).to_string(index=False)}\n\nüí° INTERPR√âTATION :\n- Coefficient > 0 ‚Üí Augmente la probabilit√© de MALIGNIT√â\n- Coefficient < 0 ‚Üí Augmente la probabilit√© de B√âNIGNIT√â\n- |Coefficient| √©lev√© ‚Üí Feature tr√®s influente dans la d√©cision\n\n9. ANALYSE DES ERREURS\n{'='*80}\nNombre total d'erreurs : {n_errors} / {len(y_test)} ({n_errors/len(y_test)*100:.2f}%)\n\nD√©tail des erreurs :\n  ‚Ä¢ Faux Positifs (pr√©dit Malin, r√©el B√©nin) : {len(false_positives)}\n  ‚Ä¢ Faux N√©gatifs (pr√©dit B√©nin, r√©el Malin) : {len(false_negatives)}\n\n‚ö†Ô∏è  En contexte m√©dical :\n- Faux N√©gatifs sont plus dangereux (cancer non d√©tect√©)\n- Faux Positifs causent du stress mais permettent des examens compl√©mentaires\n\nSeuil de d√©cision optimal : {optimal_threshold:.4f}\n  (avec ce seuil, F1-Score maximal = {max(f1_scores):.4f})\n\n10. MATRICE DE CONFUSION\n{'='*80}\n                    Pr√©diction\n                B√©nin    Malin\nR√©alit√©  B√©nin   {cm[0,0]:4d}     {cm[0,1]:4d}\n         Malin   {cm[1,0]:4d}     {cm[1,1]:4d}\n\n- Vrais N√©gatifs  : {cm[0,0]} (B√©nin correctement identifi√©)\n- Faux Positifs   : {cm[0,1]} (B√©nin pr√©dit Malin)\n- Faux N√©gatifs   : {cm[1,0]} (Malin pr√©dit B√©nin)\n- Vrais Positifs  : {cm[1,1]} (Malin correctement identifi√©)\n\n11. FICHIERS G√âN√âR√âS\n{'='*80}\n‚úì vif_analysis.png                  - Analyse VIF\n‚úì regularization_comparison.png     - Comparaison r√©gularisations\n‚úì confusion_matrix.png              - Matrice de confusion\n‚úì roc_curve.png                     - Courbe ROC\n‚úì precision_recall_curve.png        - Courbe Precision-Recall\n‚úì roc_pr_combined.png               - ROC + PR combin√©es\n‚úì feature_importance.png            - Importance des features\n‚úì calibration_analysis.png          - Analyse de calibration\n‚úì error_analysis.png                - Analyse des erreurs\n‚úì final_comparison.png              - Comparaison finale\n‚úì logistic_regression_report.txt    - Ce rapport\n\n12. CONCLUSIONS ET RECOMMANDATIONS\n{'='*80}\n‚úÖ POINTS FORTS :\n  ‚Ä¢ Excellentes performances globales (Accuracy > 95%)\n  ‚Ä¢ Bonne capacit√© de discrimination (AUC-ROC √©lev√©)\n  ‚Ä¢ Mod√®le interpr√©table (coefficients facilement analysables)\n  ‚Ä¢ Stable en validation crois√©e\n\n‚ö†Ô∏è  POINTS D'ATTENTION :\n  ‚Ä¢ Multicolin√©arit√© d√©tect√©e (g√©r√©e par r√©gularisation)\n  ‚Ä¢ Quelques erreurs de classification ({n_errors} cas)\n  ‚Ä¢ Calibration {'√† am√©liorer' if brier_score > 0.1 else 'satisfaisante'}\n\nüí° RECOMMANDATIONS :\n  1. Consid√©rer un seuil de d√©cision ajust√© ({optimal_threshold:.2f}) pour optimiser F1\n  2. Analyser en d√©tail les cas d'erreurs pour comprendre les limites\n  3. Combiner avec d'autres mod√®les (ensemble) pour am√©liorer robustesse\n  4. Valider sur des donn√©es externes pour g√©n√©ralisation\n\n13. COMPARAISON AVEC LA LITT√âRATURE\n{'='*80}\nD'apr√®s le paper de r√©f√©rence (Street et al.), les meilleures performances\n√©taient obtenues avec :\n  ‚Ä¢ Linear Programming : ~97% accuracy\n  ‚Ä¢ MLP (3-hidden)     : ~98.5% accuracy\n\nNotre mod√®le de r√©gression logistique optimis√© atteint {accuracy_opt*100:.2f}% \nd'accuracy, ce qui est {'excellent et comparable' if accuracy_opt > 0.96 else 'tr√®s bon et proche'} des r√©sultats du paper.\n\n{'='*80}\nRAPPORT G√âN√âR√â LE : {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\nAUTEUR : Personne 2 - √âquipe Breast Cancer Detection\n{'='*80}\n\"\"\"\n\nprint(report)\n\n# Sauvegarder le rapport\nwith open('logistic_regression_report.txt', 'w', encoding='utf-8') as f:\n    f.write(report)\n\nprint(\"\\n‚úì Rapport complet sauvegard√© : 'logistic_regression_report.txt'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-15T20:36:29.713141Z","iopub.status.idle":"2025-11-15T20:36:29.713572Z","shell.execute_reply.started":"2025-11-15T20:36:29.713361Z","shell.execute_reply":"2025-11-15T20:36:29.713380Z"}},"outputs":[],"execution_count":null}]}